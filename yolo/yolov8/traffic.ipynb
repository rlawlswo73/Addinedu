{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True가 출력되어야 합니다.\n",
    "print(torch.cuda.device_count())  # 사용 가능한 GPU 개수가 출력됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 표지판 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv8 모델 객체 생성 (기본적으로 COCO pre-trained 모델을 로드)\n",
    "model = YOLO('yolov8n.pt')  # 'yolov8n.pt', 'yolov8s.pt' 등 선택 가능\n",
    "\n",
    "# 모델 학습\n",
    "model.train(data='',  # yaml 파일 경로\n",
    "            epochs=50,                     # 학습 에포크 수\n",
    "            imgsz=640,                     # 이미지 크기\n",
    "            batch=16,\n",
    "            conf=0.7,\n",
    "            iou=0.65,\n",
    "            device=0)                      # 배치 크기\n",
    "\n",
    "# 학습 완료 후 결과 확인\n",
    "results = model.val(data='', iou=0.7) # 데이터셋 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신호등 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv8 모델 객체 생성\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# 모델 학습\n",
    "model.train(\n",
    "    data=\"\",  # 학습 데이터셋 경로가 포함된 .yaml 파일 경로\n",
    "    epochs=200,  # 학습 반복 수 (에포크)\n",
    "    imgsz=(320, 640),  # 입력 이미지 크기 (최소값, 최대값) - 동적 크기 조정을 위해 사용\n",
    "    batch=16,  # 배치 크기 (한 번에 학습할 이미지 개수)\n",
    "    device=0,  # 사용할 GPU 디바이스 번호 (0이면 첫 번째 GPU)\n",
    "    # num_workers=4,  # 데이터 로더에 사용할 CPU 스레드 수 (주석 처리됨)\n",
    "    mosaic=1.0,  # 모자이크 데이터 증강의 비율 (0~1 사이, 1은 항상 모자이크 사용)\n",
    "    mixup=0.2,  # MixUp 데이터 증강 비율 (0~1 사이)\n",
    "    degrees=20,  # 데이터 증강 시 이미지 회전 각도 범위 (최대 ±20도)\n",
    "    translate=0.2,  # 데이터 증강 시 이미지 평행 이동 범위 (0~1, 비율 기준)\n",
    "    scale=0.7,  # 데이터 증강 시 이미지 스케일 조정 범위 (0.7배)\n",
    "    shear=5.0,  # 데이터 증강 시 이미지 기울이기 범위 (최대 ±5도)\n",
    "    perspective=0.001,  # 데이터 증강 시 원근 변환 범위 (0~1)\n",
    "    hsv_h=0.02,  # HSV 색상 조정 중 Hue(색상)의 변동 범위 (0~1)\n",
    "    hsv_s=0.8,  # HSV 색상 조정 중 Saturation(채도)의 변동 범위 (0~1)\n",
    "    hsv_v=0.5,  # HSV 색상 조정 중 Value(명도)의 변동 범위 (0~1)\n",
    "    fliplr=0.5,  # 좌우 반전 증강의 확률 (0~1, 0.5는 50% 확률로 적용)\n",
    "    patience=30,  # 조기 종료(Early Stopping) 기준으로, 개선 없는 에포크 허용 수\n",
    "    conf=0.6,  # 학습 중 감지된 객체를 평가할 때 사용할 Confidence threshold\n",
    "    iou=0.6,  # IoU(Intersection over Union) 임계값 (0~1)\n",
    "    # workers=4,  # 데이터 로더를 위한 워커 수 (주석 처리됨)\n",
    "    project=\"./\",  # 학습 결과가 저장될 프로젝트 디렉토리\n",
    "    save=True  # 학습 후 체크포인트 및 결과 저장 여부\n",
    ")\n",
    "\n",
    "\n",
    "# 학습 완료 후 결과 확인\n",
    "results = model.val(\n",
    "    data=\"\", # 학습 데이터셋 경로가 포함된 .yaml 파일 경로\n",
    "    imgsz=640,\n",
    "    iou=0.55,\n",
    "    save_json=True,\n",
    "    project=\"./\"\n",
    ")\n",
    "\n",
    "# 학습 및 검증 결과 출력\n",
    "print(\"Validation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 카메라로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 학습된 모델 파일 경로\n",
    "MODEL_PATH = \"\" # 자신의 모델 경로로 수정\n",
    "\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# 카메라 캡처 초기화\n",
    "cap = cv2.VideoCapture(0)  # 기본 카메라 사용 (0번 장치)\n",
    "if not cap.isOpened():\n",
    "    print(\"카메라를 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 탐지 설정\n",
    "CONFIDENCE_THRESHOLD = 0.5  # 탐지 최소 신뢰도\n",
    "\n",
    "# 클래스 색상 정의 (랜덤)\n",
    "import random\n",
    "random.seed(42)\n",
    "COLORS = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for _ in range(len(model.names))]\n",
    "\n",
    "# 실시간 탐지 루프\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"카메라에서 프레임을 읽을 수 없습니다.\")\n",
    "        break\n",
    "\n",
    "    # 모델을 사용하여 탐지 수행\n",
    "    results = model.predict(\n",
    "        source=frame, \n",
    "        conf=0.5, \n",
    "        verbose=False,\n",
    "        device=0, \n",
    "        imgsz=640\n",
    "    )\n",
    "\n",
    "    # 탐지 결과를 이미지에 표시\n",
    "    detections = results[0].boxes.data.cpu().numpy()  # 탐지 결과 데이터\n",
    "    for detection in detections:\n",
    "        x1, y1, x2, y2, confidence, class_id = detection\n",
    "        class_id = int(class_id)\n",
    "        label = f\"{model.names[class_id]} {confidence:.2f}\"\n",
    "\n",
    "        # 박스 및 라벨 표시\n",
    "        color = COLORS[class_id % len(COLORS)]\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "        cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # 화면에 출력\n",
    "    cv2.imshow(\"YOLOv8 Detection\", frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 정리\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
